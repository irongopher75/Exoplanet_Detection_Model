epochs: 200
batch_size: 64
optimizer: adam
learning_rate: 0.0001
scheduler: cosine
early_stopping: bayesian_evidence
